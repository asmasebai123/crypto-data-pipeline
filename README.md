# ğŸš€ Crypto Data Pipeline â€” End-to-End

Pipeline Data Engineering complet pour collecter, traiter et visualiser les prix des cryptomonnaies en temps rÃ©el.

**ğŸŒ Dashboard en ligne** : https://crypto-data-pipeline-8mrtpexxnwydrp9dbehvt5.streamlit.app

---

## ğŸ“Š Diagramme d'architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CRYPTO DATA PIPELINE                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   SOURCES                STOCKAGE              TRAITEMENT           SORTIE
   â”€â”€â”€â”€â”€â”€â”€                â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€

CoinGecko API          PostgreSQL           Transformations      Streamlit
(batch/10min)     â”€â”€â–º   (Neon Cloud)    â”€â”€â–º     Pandas        â”€â”€â–º  Dashboard
                           â”‚                      â”‚                  (URL)
Kafka Producer            â”‚                      â”‚
(streaming/5s)     â”€â”€â–º    â”‚                  Prefect
                          â”‚                (orchestration)
                   Docker Compose
                   (dev local)
```

---

## ğŸ› ï¸ Stack technologique

| Couche | Technologie | Justification |
|--------|-------------|---------------|
| **Ingestion Batch** | Python + CoinGecko API | API publique gratuite, donnÃ©es structurÃ©es fiables |
| **Ingestion Streaming** | Apache Kafka | Standard industrie pour flux temps rÃ©el, scalable |
| **Stockage** | PostgreSQL (Neon) | DonnÃ©es structurÃ©es, requÃªtes analytiques SQL, cloud gratuit |
| **Transformation** | Pandas | Volume modÃ©rÃ© (~5000 lignes), dÃ©veloppement rapide |
| **Orchestration** | Prefect | Dashboard intÃ©grÃ©, retry automatique, plus simple qu'Airflow |
| **Visualisation** | Streamlit + Plotly | DÃ©ploiement rapide, interface interactive, gratuit |
| **DÃ©ploiement** | Docker Compose + Cloud | ReproductibilitÃ© locale + accessibilitÃ© publique |

---

## ğŸ“‚ Structure du projet
```
crypto_data_project/
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ main.py                 # Ingestion batch CoinGecko (10 min)
â”‚   â”œâ”€â”€ database.py             # Connexion PostgreSQL + crÃ©ation tables
â”‚   â”œâ”€â”€ kafka_producer.py       # Producteur Kafka (simulation)
â”‚   â”œâ”€â”€ kafka_consumer.py       # Consommateur Kafka â†’ PostgreSQL
â”‚   â”œâ”€â”€ fetch_history.py        # RÃ©cupÃ©ration historique rÃ©el
â”‚   â””â”€â”€ migrate_to_neon.py      # Migration donnÃ©es vers cloud
â”œâ”€â”€ transformations/
â”‚   â”œâ”€â”€ cleaning.py             # Nettoyage (nulls, doublons, outliers)
â”‚   â”œâ”€â”€ aggregations.py         # Moyenne horaire + volume journalier
â”‚   â”œâ”€â”€ rankings.py             # Classement par performance 24h
â”‚   â”œâ”€â”€ alerts.py               # DÃ©tection variations > Â±5%
â”‚   â””â”€â”€ run_transforms.py       # Pipeline complet transformations
â”œâ”€â”€ orchestration/
â”‚   â”œâ”€â”€ flows.py                # Flows Prefect avec retry
â”‚   â””â”€â”€ scheduler.py            # Planification automatique
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ app.py                  # Dashboard Streamlit principal
â”‚   â””â”€â”€ config.py               # Configuration multi-environnement
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_transformations.py # 18 tests unitaires
â”œâ”€â”€ docker-compose.yml          # PostgreSQL + Kafka + Zookeeper
â”œâ”€â”€ requirements.txt            # DÃ©pendances Python
â”œâ”€â”€ .env.example               # Template configuration
â””â”€â”€ README.md                   # Documentation (ce fichier)
```

---

## ğŸ“¡ Sources de donnÃ©es

### Source 1 â€” Batch (CoinGecko API)
- **Endpoint** : `https://api.coingecko.com/api/v3/coins/markets`
- **FrÃ©quence** : Toutes les 10 minutes
- **DonnÃ©es** : Prix, volume, capitalisation, variation 24h
- **Cryptos** : Bitcoin, Ethereum, Solana, XRP, BNB
- **Plan** : Gratuit (avec clÃ© API)

### Source 2 â€” Streaming (Kafka)
- **Topic** : `crypto_prices`
- **Producteur** : Simulation de variations de prix rÃ©alistes
- **FrÃ©quence** : Toutes les 5 secondes
- **DonnÃ©es** : Prix + variation instantanÃ©e

---

## ğŸ”„ Transformations mÃ©tier

| # | Transformation | Fichier | Description |
|---|----------------|---------|-------------|
| 1 | **Nettoyage** | `cleaning.py` | Suppression nulls, doublons, prix aberrants (<0) |
| 2 | **Moyenne horaire** | `aggregations.py` | Prix moyen/min/max par crypto par heure |
| 3 | **Volume journalier** | `aggregations.py` | Volume total Ã©changÃ© par jour |
| 4 | **Classement** | `rankings.py` | Ranking par performance 24h (meilleur = rang 1) |
| 5 | **Alertes** | `alerts.py` | DÃ©tection variation > Â±5% (hausse/baisse forte) |

**Exemple de rÃ©sultat** :
```
Alerte dÃ©tectÃ©e : Bitcoin +12.87% (HAUSSE FORTE) - Prix: $59,905.71
```

---

## âš™ï¸ Orchestration

- **Outil** : Prefect 3.x
- **FrÃ©quence** : Pipeline complet toutes les 10 minutes
- **Retry** : 3 tentatives automatiques sur Ã©chec API
- **DÃ©pendances** : Ingestion â†’ Nettoyage â†’ Transformations â†’ Alertes
- **Logs** : SauvegardÃ©s dans `logs/` avec horodatage

**Flow principal** :
```python
1. CrÃ©er tables si nÃ©cessaire
2. Appeler API CoinGecko (avec retry)
3. Sauvegarder donnÃ©es brutes
4. Nettoyer les donnÃ©es
5. Calculer transformations en parallÃ¨le
6. GÃ©nÃ©rer rapport de synthÃ¨se
```

---

## ğŸ–¥ï¸ Dashboard interactif

**URL publique** : https://crypto-data-pipeline-8mrtpexxnwydrp9dbehvt5.streamlit.app

**FonctionnalitÃ©s** :
- ğŸ“Š Graphique Ã©volution des prix sur 7 jours (Plotly interactif)
- ğŸ† Top 5 cryptos du jour par performance
- âš ï¸ Alertes de volatilitÃ© en temps rÃ©el (seuil configurable)
- ğŸ“ˆ Volume journalier Ã©changÃ© par crypto
- ğŸ”„ Actualisation automatique toutes les 60 secondes
- ğŸ“± Responsive (mobile, tablette, desktop)

---

## ğŸš€ Installation et dÃ©marrage

### PrÃ©requis
- **Docker Desktop** (installÃ© et dÃ©marrÃ©)
- **Python 3.10+**
- **Git**
- **ClÃ© API CoinGecko** (gratuite sur coingecko.com)

### Installation rapide
```bash
# 1. Cloner le dÃ©pÃ´t
git clone https://github.com/asmasebai123/crypto-data-pipeline.git
cd crypto-data-pipeline

# 2. CrÃ©er l'environnement virtuel
python -m venv venv
venv\Scripts\activate        # Windows
source venv/bin/activate     # Linux/Mac

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. Configurer les variables d'environnement
cp .env.example .env
# Ã‰diter .env et ajouter ta clÃ© CoinGecko

# 5. DÃ©marrer les services Docker
docker compose up -d

# 6. Initialiser la base de donnÃ©es
python ingestion/database.py

# 7. Lancer le pipeline complet
python orchestration/flows.py

# 8. Lancer le dashboard (optionnel en local)
streamlit run dashboard/app.py
```

**Dashboard accessible sur** : http://localhost:8501

---

## ğŸ§ª Tests
```bash
# Lancer tous les tests
pytest tests/ -v

# RÃ©sultat attendu
======================== 18 passed in 0.42s ========================
```

**Tests couverts** :
- Nettoyage des donnÃ©es (5 tests)
- AgrÃ©gations (3 tests)
- DÃ©tection d'alertes (5 tests)
- Classement (2 tests)
- QualitÃ© des donnÃ©es (3 tests)

---

## ğŸ”§ DifficultÃ©s rencontrÃ©es et solutions

| ProblÃ¨me | Solution |
|----------|----------|
| **SSL Certificate Error** (rÃ©seau universitaire) | `verify=False` + `urllib3.disable_warnings` |
| **CoinGecko 403 Forbidden** (nouvelle politique) | Inscription gratuite + clÃ© API dans headers |
| **kafka-python incompatible Python 3.12** | Migration vers `kafka-python-ng` |
| **DÃ©ploiement cloud base de donnÃ©es** | Neon PostgreSQL gratuit + migration script |
| **requirements.txt Anaconda paths** | Nettoyage manuel + librairies essentielles uniquement |

---

## ğŸ“ˆ RÃ©sultats

- **DonnÃ©es collectÃ©es** : ~5050 lignes sur 7 jours (5 cryptos Ã— 168 points/jour)
- **FrÃ©quence mise Ã  jour** : Toutes les 10 minutes (batch) + 5 secondes (streaming)
- **Uptime dashboard** : 24/7 via Streamlit Cloud
- **Temps de rÃ©ponse** : <2 secondes (requÃªtes PostgreSQL)
- **Tests** : 100% de passage (18/18)

---

## ğŸ¯ Limites et perspectives d'amÃ©lioration

### Limites actuelles
- Volume limitÃ© : 5 cryptos uniquement
- GranularitÃ© : donnÃ©es horaires (API gratuite)
- Streaming : simulation, pas de vraie connexion WebSocket
- Pandas : limite ~1M lignes (pas scalable pour big data)

### AmÃ©liorations possibles
1. **ScalabilitÃ©** : Remplacer Pandas par PySpark pour gros volumes
2. **Real-time** : Connexion WebSocket directe aux exchanges (Binance, Coinbase)
3. **ML/AI** : ModÃ¨le prÃ©dictif des prix (LSTM, Prophet)
4. **Alertes** : Notifications Slack/Email sur alertes critiques
5. **Monitoring** : Grafana + Prometheus pour mÃ©triques pipeline
6. **CI/CD** : GitHub Actions pour tests automatiques

---

## ğŸ“¦ DÃ©ploiement

### Environnement de dÃ©veloppement (local)
```bash
docker compose up -d
python orchestration/flows.py
streamlit run dashboard/app.py
```

### Environnement de production (cloud)
- **Dashboard** : Streamlit Cloud (https://...streamlit.app)
- **Base de donnÃ©es** : Neon PostgreSQL (eu-central-1)
- **Logs** : Dossier `logs/` avec rotation automatique

---

## ğŸ‘¤ Auteur

**Asma SEBAI**  
IngÃ©nieur Data | ING2 S2  
ğŸ“§ asmasebai2003@gmail.com  
ğŸ”— [GitHub](https://github.com/asmasebai123) | [LinkedIn](https://linkedin.com/in/asmasebai)

---

## ğŸ“„ Licence

Ce projet est un projet acadÃ©mique rÃ©alisÃ© dans le cadre du cours de Data Engineering.

---

## ğŸ™ Remerciements

- **CoinGecko** pour l'API publique gratuite
- **Neon** pour l'hÃ©bergement PostgreSQL gratuit
- **Streamlit** pour la plateforme de dÃ©ploiement
- **Anthropic Claude** pour l'assistance technique

---

**â­ N'oubliez pas de star le repo si ce projet vous a aidÃ© !**